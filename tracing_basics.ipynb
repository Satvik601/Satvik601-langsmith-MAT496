{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set your environment variables, including your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing with @traceable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The @traceable decorator is a simple way to log traces from the LangSmith Python SDK. Simply decorate any function with @traceable.\n",
    "\n",
    "The decorator works by creating a run tree for you each time the function is called and inserting it within the current trace. The function inputs, name, and other information is then streamed to LangSmith. If the function raises an error or if it returns a response, that information is also added to the tree, and updates are patched to LangSmith so you can detect and diagnose sources of errors. This is all done on a background thread to avoid blocking your app's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "# TODO: Set up tracing for each function\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)   # NOTE: This is a LangChain vector db retriever, so this .invoke() call will be traced automatically\n",
    "\n",
    "\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@traceable handles the RunTree lifecycle for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I trace with the @traceable decorator?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith supports sending arbitrary metadata along with traces.\n",
    "\n",
    "Metadata is a collection of key-value pairs that can be attached to runs. Metadata can be used to store additional information about a run, such as the version of the application that generated the run, the environment in which the run was generated, or any other information that you want to associate with a run. Similar to tags, you can use metadata to filter runs in the LangSmith UI, and can be used to group runs together for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(\n",
    "     metadata={\"vectordb\": \"sklearn\"}\n",
    " )\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "      # Debug line added\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "@traceable(\n",
    "    metadata={\"model_name\": MODEL_NAME, \"model_provider\": MODEL_PROVIDER}\n",
    " )\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sent to model: list(\n",
      "    my_streaming_chat_model(\n",
      "        [\n",
      "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please greet the user.\"},\n",
      "            {\"role\": \"user\", \"content\": \"polly the parrot\"},\n",
      "        ],\n",
      "    )\n",
      ")\n",
      "\n",
      "If ls_model_name is not present in extra.metadata, other fields might be used from the extra.metadata for estimating token counts. The following fields are used in the order of precedence:\n",
      "metadata.ls_model_name\n",
      "inputs.model\n",
      "inputs.model_name\n",
      "\n",
      "​Provide token and cost information\n",
      "By default, LangSmith uses tiktoken to count tokens, utilizing a best guess at the model’s tokenizer based on the ls_model_name provided. It also calculates costs automatically by using the model pricing table. To learn how LangSmith calculates token-based costs, see this guide.\n",
      "However, many models already include exact token counts as part of the response. If you have this information, you can override the default token calculation in LangSmith in one of two ways:\n",
      "\n",
      "Extract usage within your traced function and set a usage_metadata field on the run’s metadata.\n",
      "Return a usage_metadata field in your traced function outputs.\n",
      "\n",
      "for output_dict, reference_output_dict in zip(outputs, reference_outputs):\n",
      "        output = output_dict[\"class\"]\n",
      "        reference_output = reference_output_dict[\"class\"]\n",
      "\n",
      "        if output == \"Toxic\" and reference_output == \"Toxic\":\n",
      "            true_positives += 1\n",
      "        elif output == \"Toxic\" and reference_output == \"Not toxic\":\n",
      "            false_positives += 1\n",
      "        elif output == \"Not toxic\" and reference_output == \"Toxic\":\n",
      "            false_negatives += 1\n",
      "\n",
      "    if true_positives == 0:\n",
      "        return {\"key\": \"f1_score\", \"score\": 0.0}\n",
      "\n",
      "    precision = true_positives / (true_positives + false_positives)\n",
      "    recall = true_positives / (true_positives + false_negatives)\n",
      "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
      "\n",
      "    return {\"key\": \"f1_score\", \"score\": f1_score}\n",
      "\n",
      "You can then pass this evaluator to the evaluate method as follows:\n",
      "PythonTypeScriptCopyfrom langsmith import Client\n",
      "\n",
      "ls_client = Client()\n",
      "dataset = ls_client.clone_public_dataset(\n",
      "    \"https://smith.langchain.com/public/3d6831e6-1680-4c88-94df-618c8e01fc55/d\"\n",
      ")\n",
      "\n",
      "def bad_classifier(inputs: dict) -> dict:\n",
      "    return {\"class\": \"Not toxic\"}\n",
      "\n",
      "def correct(outputs: dict, reference_outputs: dict) -> bool:\n",
      "    \"\"\"Row-level correctness evaluator.\"\"\"\n",
      "    return outputs[\"class\"] == reference_outputs[\"label\"]\n",
      "\n",
      "You can configure retention through helm or environment variable settings. There are a few options that are configurable:\n",
      "\n",
      "Delete workspaces - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewSetupInstall on KubernetesInstall on DockerInteract with an installationUpgrade an installationConfigure egress for subscription metricsView trace counts across an organizationLangSmith-managed ClickHouseConfigurationConfigure for scaleEnable TTL & data retentionCreate an Ingress for installations (Kubernetes)Mirror images for your installationUse environment variables for model providersTroubleshootingAuthentication & access controlSet up basic authenticationSet up SSO with OAuth2.0 & OIDCCustomize user managementConfigure custom TLS certificatesUse an existing secret for your installation (Kubernetes)Connect external servicesEnable blob storageConnect to an external ClickHouse databaseConnect to an external PostgreSQL databaseConnect to an external Redis databaseScriptsDelete workspacesDelete organizationsDelete tracesGenerate ClickHouse StatsGenerate query statsRun support queries against PostgreSQLRun support queries against ClickHouseObservabilityExport LangSmith telemetry to your observability backendConfigure your collector for telemetryDeploy an observability stackOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationScriptsDelete workspacesGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pagePrerequisitesRunning the deletion script for a single workspaceScriptsDelete workspacesCopy pageCopy pageDeleting a workspace is supported nativley in LangSmith Self-Hosted v0.10. View instructions for deleting a workspace.Follow the guide below for Self-Hosted versions before v0.10.\n",
      "The LangSmith UI does not currently support the deletion of an individual workspace from an organization. This, however, can be accomplished by directly removing all traces from all materialized views in ClickHouse (except the runs_history views) and the runs and feedbacks tables and then removing the Workspace from the Postgres tenants table.\n",
      "This command using the Workspace ID as an argument.\n",
      "​Prerequisites\n",
      "To add metadata to a run with `@traceable`, you can set a `usage_metadata` field within your traced function. This field can include any relevant metadata you want to associate with the run. Alternatively, you can return a `usage_metadata` field in the outputs of your traced function.\n",
      "To add metadata to a run with `@traceable`, you can set a `usage_metadata` field within your traced function. This field can include any relevant metadata you want to associate with the run. Alternatively, you can return a `usage_metadata` field in the outputs of your traced function.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I add Metadata to a Run with @traceable?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add metadata at runtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sent to model: \"response\": \"Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99\",\n",
      "            \"trajectory\": [\"refund_agent\", \"lookup\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n",
      "            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "\n",
      "\"response\": 'Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99',\n",
      "            \"trajectory\": [\"refund_agent\", \"lookup\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n",
      "            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "\n",
      "@traceable(run_type=\"retriever\")\n",
      "def retrieve(query: str) -> list:\n",
      "    \"\"\"Get up to two search wikipedia results.\"\"\"\n",
      "    results = []\n",
      "    for term in wp.search(query, results = 10):\n",
      "        try:\n",
      "            page = wp.page(term, auto_suggest=False)\n",
      "            results.append({\n",
      "                \"page_content\": page.summary,\n",
      "                \"type\": \"Document\",\n",
      "                \"metadata\": {\"url\": page.url}\n",
      "            })\n",
      "        except wp.DisambiguationError:\n",
      "            pass\n",
      "        if len(results) >= 2:\n",
      "            return results\n",
      "\n",
      "@traceable\n",
      "def generate_answer(question: str, context: str) -> str:\n",
      "    \"\"\"Answer the question based on the retrieved information.\"\"\"\n",
      "    instructions = f\"Answer the user's question based ONLY on the content below:\\n\\n{context}\"\n",
      "    messages = [\n",
      "        {\"role\": \"system\", \"content\": instructions},\n",
      "        {\"role\": \"user\", \"content\": question}\n",
      "    ]\n",
      "    result = oai_client.chat.completions.create(\n",
      "        messages=messages,\n",
      "        model=\"gpt-4o-mini\",\n",
      "        temperature=0\n",
      "    )\n",
      "    return result.choices[0].message.content\n",
      "\n",
      "\"content\": \"I've refunded you a total of $1.98. How else can I help you today?\",\n",
      "                },\n",
      "                {\"role\": \"user\", \"content\": \"did prince release any albums in 2000?\"},\n",
      "            ],\n",
      "        },\n",
      "        \"outputs\": {\"route\": \"question_answering_agent\"},\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"messages\": [\n",
      "                {\n",
      "                    \"role\": \"user\",\n",
      "                    \"content\": \"i purchased a cover of Yesterday recently but can't remember who it was by, which versions of it do you have?\",\n",
      "                }\n",
      "            ],\n",
      "        },\n",
      "        \"outputs\": {\"route\": \"question_answering_agent\"},\n",
      "    },\n",
      "]\n",
      "I don't know.\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I add metadata at runtime?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"runtime_metadata\": \"foo\"}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
